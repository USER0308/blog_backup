
## 背景

网上图书管理系统需要用到大量书籍信息，为了确保真实性，选择从豆瓣网上爬取。豆瓣网开放了 API，提供书籍信息，只需向特定 URL POST 指定参数然后获取书籍信息保存下来即可。

## 难点

豆瓣存在着限制请求次数系统，一个小时内只能请求 50 次，多于该次数则 response 返回内容为空，需要每个一个小时爬取一次，每次爬取 50 个书籍信息

## 爬虫代码

代码分为三个部分，book.py 定义了书籍 Book 类和保存书籍信息到文件系统中的 save_book_info 方法，spider.py 定义了爬虫 Spider 类，负责将参数和基本 URL 拼凑成完整的 URL 的 comtact 方法，爬取书籍的 craw 方法，从文件中读取参数的 read_book_num 方法，把更新后参数保存到文件中的 write_book_num 方法，main.py 负责传入基本 URL 并启动爬虫程序。

main.py

```

# coding=utf-8
'''ensure coding with utf-8'''
import time
from spider import Spider

if __name__ == '__main__':
    INDEX_URL = 'https://api.douban.com/v2/book/'
    spider = Spider(INDEX_URL)
    print spider.book_num
    for i in range(1, 50):  # 50
        time.sleep(1)
        spider.comtact()
        spider.craw()
    spider.write_book_num()

```

spider.py

```

# encoding=utf-8
'''ensure the coding is utf-8'''
import urllib
import json
from book import Book
class Spider(object):
    '''a class of spider to craw book'''
    base_url = None
    full_book_url = None
    book_num = 0

    def __init__(self, base_url):
        '''initial the spider model '''
        self.base_url = base_url
        self.book_num = self.read_book_num()

    def comtact(self):
        '''comtact the base url with book_num'''
        self.full_book_url = self.base_url + str(self.book_num)
        self.book_num += 1
        print self.full_book_url

    def craw(self):
        '''craw the book info'''
        response = urllib.urlopen(self.full_book_url).read()
        #print response
        #print type(response)
        json_response = json.loads(response)
        if json_response.has_key("code"):
            print json_response["code"]
            print json_response["msg"]
            return
        book = Book(json_response["isbn13"],
                    json_response["title"],
                    json_response["author"],
                    json_response["publisher"],
                    json_response["tags"],
                    json_response["summary"],
                    json_response["image"])
        book.print_book_info()
        book.save_book_info()

    def read_book_num(self):
        f = open('/home/user0308/projects/crontab/data/book_num.txt')
        book_num = f.read()
        f.close()
#        print book_num
#        print type(int(book_num))
        return int(book_num)

    def write_book_num(self):
        f = open('/home/user0308/projects/crontab/data/book_num.txt','w')
        f.write(str(self.book_num))
        f.close()

```

book.py

```

# encoding=utf-8
'''ensure the coding is utf-8'''
import codecs

class Book(object):
    '''a class of book'''
    isbn = None
    title = None
    authors = None
    publisher = None
    tags = None
    summary = None
    image_url = None
    def __init__(self, isbn, title, authors, publisher, tags, summary, image_url):
        '''initial the book model '''
        self.isbn = isbn
        self.title = title
        self.authors = authors
        self.publisher = publisher
        self.tags = tags
        self.summary = summary
        self.image_url = image_url

    def print_book_info(self):
        '''print the book information'''
#        print "isbn=", self.isbn
#        print "title=", self.title
#        print "author=",
#        for author in self.authors:
#            print author.encode('utf-8'),
#        print
#        print "publisher=", self.publisher
#        print "tags=",
#        for tag in self.tags:
#            print tag["name"],
#        print
#        print "summary=", self.summary
#        print "image_url=", self.image_url

    def save_book_info(self):
        '''save the book info into a .txt file'''
        file_handler = codecs.open('/home/user0308/projects/crontab/data/book_info.txt', 'a', 'utf-8')
        file_handler.write("\nisbn:")
        file_handler.write(self.isbn)
        file_handler.write("\ntitle:")
        file_handler.write(self.title)
        file_handler.write("\nauthor:")
        for author in self.authors:
            file_handler.write(author),
            file_handler.write(", "),
        #
        file_handler.write("\npublisher:")
        file_handler.write(self.publisher)
        file_handler.write("\ntag:")
        for tag in self.tags:
            file_handler.write(tag["name"]),
            file_handler.write(", "),
        #file_handler.write()
        file_handler.write("\nsummary:")
        file_handler.write(self.summary)
        file_handler.write("\nimage_url:")
        file_handler.write(self.image_url)
        file_handler.close()

```

最后的定时则由 Linux 系统的 crontab 实现。值得注意的是，需要在 crontab 中指定完整路径

```

$ crontab -e

* */1 * * * /usr/bin/python2.7 /home/user0308/projects/crontab/data/main.py >> /home/user0308/projects/crontab/logs

```
